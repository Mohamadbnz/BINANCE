# ğŸš€ Real-Time Cryptocurrency Market Data Pipeline

A **pipeline** that ingests live cryptocurrency market data from Binance WebSocket, processes it through Apache Kafka, and enables real-time analytics and visualization.

**Built to demonstrate:** Stream processing â€¢ Event-driven architecture â€¢ Scalable data engineering â€¢ Real-time analytics

![Python](https://img.shields.io/badge/Python-3.9+-blue)
![Kafka](https://img.shields.io/badge/Kafka-3.0+-orange)
![License](https://img.shields.io/badge/license-MIT-green)

[Live Demo Video](link-if-you-have-one) | [Architecture Diagram](https://github.com/Mohamadbnz/BINANCE/edit/main/README.md#%EF%B8%8F-architecturehttps://github.com/Mohamadbnz/BINANCE/edit/main/README.md#%EF%B8%8F-architecture)

---

## ğŸ¯ Key Features

- âš¡ **Real-time streaming** with sub-second latency
- ğŸ”„ **Event-driven architecture** using Apache Kafka
- ğŸ“Š **Live visualization** with candlestick charts
- ğŸ“ˆ **Scalable design** supporting multiple symbols/intervals
---

## ğŸ“ **Project Structure**
```
BINANCE/
â”œâ”€â”€ producer.py
â”œâ”€â”€ consumer.py
â”œâ”€â”€ visualizer.py
â”œâ”€â”€ config.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

```

---

## **Files Overview**

| File            | Description                                                        |
|-----------------|--------------------------------------------------------------------|
| `producer.py`   | Fetches live candle data from Binance and publishes it to Kafka.   |
| `consumer.py`   | Subscribes to the Kafka topic and processes candle messages.       |
| `visualizer.py` | Real-time visualization of incoming candle data.                   |
| `config.py`     | Central configuration for Kafka, topics, symbols, intervals.       |

---

## âš™ï¸ **Installation**

### **1. Clone the repository**
git clone git@github.com:mohammadbnz74/BINANCE.git
cd BINANCE

### **2. Install dependencies**

pip install -r requirements.txt

### **3. Configure the project**

All settings are in config.py:

KAFKA_BOOTSTRAP = "localhost:9092"

TOPIC_CANDLES = "candles_1m"

GROUP_ID = "binance_consumer_01"

BINANCE_SYMBOL = "BTCUSDT"

INTERVAL = "1m"

---

## ğŸš€ **Usage**
### **Start Kafka**

    docker compose up -d

### **Run the producer**

    python producer.py

Fetches live candles from Binance and publishes them to Kafka.
### **Run the consumer**

    python consumer.py

Consumes candle messages and processes them.
### **Run the visualizer**

    python visualizer.py

Displays live-updating candle charts.

---

## ğŸ—ï¸ Architecture
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Binance WebSocket â”‚  (Live market data)
â”‚   API (BTCUSDT 1m)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚ candle updates
           â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Producer    â”‚  (producer.py)
    â”‚  â€¢ Connects  â”‚
    â”‚  â€¢ Validates â”‚
    â”‚  â€¢ Publishes â”‚
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   Apache Kafka       â”‚
    â”‚   Topic: candles_1m  â”‚  (Message queue)
    â”‚   â€¢ Persistence      â”‚
    â”‚   â€¢ Replay capabilityâ”‚
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â–¼                 â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚Consumer  â”‚    â”‚ Visualizer   â”‚
    â”‚(Group 1) â”‚    â”‚ â€¢ Real-time  â”‚
    â”‚Storage â”‚      â”‚ â€¢ Candlestickâ”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Design Principles:**
- **Decoupling**: Components communicate via Kafka, can be deployed independently
- **Scalability**: Add more consumers without affecting producer
- **Fault Tolerance**: Kafka persists messages if consumer fails
- **Replayability**: Can reprocess historical data from any point

    Visualizer is decoupled and customizable

